{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "import scipy.interpolate as interpolate\n",
    "from scipy.stats import skewnorm, beta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"switrs.sqlite\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM collisions WHERE county_location = 'los angeles'\n",
    "    \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, con, parse_dates = [\"collision_date\"])\n",
    "df[\"year\"] = df[\"collision_date\"].dt.year\n",
    "df[\"hour\"] = pd.to_datetime(df[\"collision_time\"], format = \"%H:%M:%S\").dt.hour\n",
    "df = df.query(\"year < 2021\") # remove incomplete 2021 data\n",
    "df[\"alcohol_involved\"] = df[\"alcohol_involved\"].fillna(0) # convert NaN to 0 in alcohol use column\n",
    "\n",
    "dfc = df[[\"case_id\", \"county_location\", \"alcohol_involved\", \"collision_severity\", \"injured_victims\", \"collision_date\", \"year\", \"collision_time\", \"hour\", \"party_count\", \"hit_and_run\", \"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data frame\n",
    "dftod = pd.DataFrame()\n",
    "dftod[\"hour\"] = range(0, 24)\n",
    "dftod[\"p\"] = dfc.groupby(\"hour\")[\"alcohol_involved\"].mean()\n",
    "dftod[\"adj_hour\"] = [16, 17, 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# fit and scale skewnormal\n",
    "shape, loc, scale = skewnorm.fit(dftod[\"p\"])\n",
    "dftod[\"p_fit\"] = skewnorm.pdf(dftod[\"p\"], shape, loc, scale)\n",
    "dftod[\"p_fit_scale\"] = -dftod[\"p_fit\"] / max(dftod[\"p_fit\"]) * max(dftod[\"p\"]) + abs(max(dftod[\"p\"]) + min(dftod[\"p\"])) # scale\n",
    "\n",
    "# plot fit against test data\n",
    "palc_base = alt.Chart(dftod).mark_bar(width = 20).encode(\n",
    "    x = alt.X(\"adj_hour\", title = \"Hour of day\", scale = alt.Scale(domain = [-0.5, 23.5]),\n",
    "               axis = alt.Axis(labelExpr = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\")),\n",
    "    y = alt.Y(\"p\", title = \"Proportion of accidents with alcohol involved\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "palc_fit = alt.Chart(dftod).mark_line(color = \"red\").encode(\n",
    "    x = alt.X(\"adj_hour\", title = \"Hour of day\", scale = alt.Scale(domain = [-0.5, 23.5]),\n",
    "               axis = alt.Axis(labelExpr = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\")),\n",
    "    y = alt.Y(\"p_fit\", title = \"Proportion of accidents with alcohol involved\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "palc_fit_scale = alt.Chart(dftod).mark_line(color = \"red\").encode(\n",
    "    x = alt.X(\"adj_hour\", title = \"Hour of day\", scale = alt.Scale(domain = [-0.5, 23.5]),\n",
    "               axis = alt.Axis(labelExpr = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\")),\n",
    "    y = alt.Y(\"p_fit_scale\", title = \"Proportion of accidents with alcohol involved\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "(palc_base + palc_fit).display()\n",
    "(palc_base + palc_fit_scale).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING SKEWNORMAL HERE\n",
    "\n",
    "# build data frame\n",
    "dftod = pd.DataFrame()\n",
    "dftod[\"hour\"] = range(0, 24)\n",
    "dftod[\"p\"] = dfc.groupby(\"hour\")[\"alcohol_involved\"].mean()\n",
    "dftod[\"adj_hour\"] = [16, 17, 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# fit and scale skewnormal\n",
    "mean, var, skew, kurt = beta.fit(dftod[\"p\"])\n",
    "\n",
    "\n",
    "\n",
    "dftod[\"p_fit\"] = beta.pdf(dftod[\"p\"], mean, var, skew, kurt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot fit against test data\n",
    "palc_base = alt.Chart(dftod).mark_bar(width = 20).encode(\n",
    "    x = alt.X(\"hour\", title = \"Hour of day\", scale = alt.Scale(domain = [-0.5, 23.5]),\n",
    "               axis = alt.Axis(labelExpr = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\")),\n",
    "    y = alt.Y(\"p\", title = \"Proportion of accidents with alcohol involved\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "palc_fit = alt.Chart(dftod).mark_line(color = \"red\").encode(\n",
    "    x = alt.X(\"hour\", title = \"Hour of day\", scale = alt.Scale(domain = [-0.5, 23.5]),\n",
    "               axis = alt.Axis(labelExpr = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\")),\n",
    "    y = alt.Y(\"p_fit\", title = \"Proportion of accidents with alcohol involved\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "(palc_base + palc_fit).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfc.groupby(\"hour\")[\"hour\"].mean()\n",
    "ya = dfc[dfc[\"alcohol_involved\"] == 1].groupby(\"hour\")[\"alcohol_involved\"].count() / len(dfc[dfc[\"alcohol_involved\"] == 1])\n",
    "yn = dfc[dfc[\"alcohol_involved\"] == 0].groupby(\"hour\")[\"alcohol_involved\"].count() / len(dfc[dfc[\"alcohol_involved\"] == 0])\n",
    "adj_hour = [16, 17, 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "adjlabel = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\"\n",
    "\n",
    "dfah = pd.DataFrame({\"hour\": x, \"adj_hour\": adj_hour, \"collisions_a\": ya, \"collisions_n\": yn})\n",
    "\n",
    "pla = alt.Chart(dfah).mark_bar(width = 20, color = \"orange\", opacity = 0.75).encode(\n",
    "    x = alt.X(\"adj_hour:O\", title = \"Hour of the day\", axis = alt.Axis(labelExpr = adjlabel)),\n",
    "    y = alt.Y(\"collisions_a\", title = \"Number of collisions (alcohol involved)\").stack(None)\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "pln = alt.Chart(dfah).mark_bar(width = 20, opacity = 0.75).encode(\n",
    "    x = alt.X(\"adj_hour:O\", title = \"Hour of the day\", axis = alt.Axis(labelExpr = adjlabel)),\n",
    "    y = alt.Y(\"collisions_n\", title = \"Number of collisions (alcohol not involved)\").stack(None)\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "(pln + pla).resolve_axis(y = \"independent\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfc.groupby(\"hour\")[\"hour\"].mean()\n",
    "y = dfc.groupby(\"hour\")[\"alcohol_involved\"].mean()\n",
    "xx = np.linspace(x.min(), x.max(), 24)\n",
    "\n",
    "t, c, k = interpolate.splrep(x, y, k = 3, s = 0.0001)\n",
    "ypred = interpolate.splev(xx, (t, c, k))\n",
    "\n",
    "adj_hour = [16, 17, 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "dfspl = pd.DataFrame({\"hour\": x, \"adj_hour\": adj_hour, \"p\": y, \"p_fit\": ypred})\n",
    "\n",
    "spl_rmse = mean_squared_error(dfspl[\"p\"], dfspl[\"p_fit\"])\n",
    "print(\"Root mean squared error: %.5f\" % (np.sqrt(spl_rmse)))\n",
    "\n",
    "adjlabel = \"{0: '8am', 1: '9am', 2: '10am', 3: '11am', 4: '12pm', 5: '1pm', 6: '2pm', 7: '3pm', 8: '4pm', 9: '5pm', 10: '6pm', 11: '7pm', 12: '8pm', 13: '9pm', 14: '10pm', 15: '11pm', 16: '12am', 17: '1am', 18: '2am', 19: '3am', 20: '4am', 21: '5am', 22: '6am', 23: '7am'}[datum.value]\"\n",
    "adjscale = alt.Scale(domain = [-0.5, 23.5])\n",
    "\n",
    "spl_base = alt.Chart(dfspl).mark_bar(width = 20).encode(\n",
    "    x = alt.X(\"hour\"),\n",
    "    y = alt.Y(\"p\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "spl = alt.Chart(dfspl).mark_line(color = \"red\").encode(\n",
    "    x = alt.X(\"hour\"),\n",
    "    y = alt.Y(\"p_fit\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "(spl_base + spl).display()\n",
    "\n",
    "spl_base = alt.Chart(dfspl).mark_bar(width = 20, color = \"orange\").encode(\n",
    "    x = alt.X(\"adj_hour\", axis = alt.Axis(labelExpr = adjlabel)),\n",
    "    y = alt.Y(\"p\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "spl = alt.Chart(dfspl).mark_line(color = \"red\").encode(\n",
    "    x = alt.X(\"adj_hour\", title = \"Hour of the day\", scale = adjscale),\n",
    "    y = alt.Y(\"p_fit\", title = \"Probability of alcohol involvement\")\n",
    ").properties(width = 600, height = 200)\n",
    "\n",
    "(spl_base + spl).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dfc.groupby(\"hour\")[\"alcohol_involved\"].mean()\n",
    "hour = dfc.groupby(\"hour\")[\"hour\"].mean()\n",
    "\n",
    "sinhour = np.sin(2 * np.pi * hour / 24)\n",
    "coshour = np.cos(2 * np.pi * hour / 24)\n",
    "\n",
    "dfcyc = pd.DataFrame({\"hour\": hour, \"sinhour\": sinhour, \"coshour\": coshour, \"p\": p})\n",
    "\n",
    "alt.Chart(dfcyc).mark_circle(size = 500).encode(\n",
    "    x = \"sinhour\",\n",
    "    y = \"coshour\",\n",
    "    color = alt.Color(\"p\", scale = alt.Scale(scheme = \"cividis\"))\n",
    ").display()\n",
    "\n",
    "bs = sm.gam.BSplines(\n",
    "    dfcyc[[\"sinhour\", \"coshour\"]],\n",
    "    df = [4, 4],\n",
    "    degree = [3, 3]\n",
    ")\n",
    "\n",
    "import statsmodels.sandbox.distributions.extras as sme\n",
    "\n",
    "gam_bs = sm.gam.GLMGam(p, dfcyc[[\"sinhour\", \"coshour\"]], smoother = bs, family = sm.families.Binomial())\n",
    "res_bs = gam_bs.fit()   \n",
    "res_bs.summary()\n",
    "\n",
    "dfcyc[\"preds\"] = res_bs.predict()\n",
    "dfcyc[\"adj_hour\"] = [16, 17, 18, 19, 20, 21, 22, 23, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "cyc_base = alt.Chart(dfcyc).mark_bar(width = 20).encode(\n",
    "    x = \"adj_hour\",\n",
    "    y = \"p\"\n",
    ").properties(width = 600, height = 300)\n",
    "\n",
    "cyc_fit = alt.Chart(dfcyc).mark_line(color = \"red\").encode(\n",
    "    x = \"adj_hour\",\n",
    "    y = \"preds\"\n",
    ").properties(width = 600, height = 300)\n",
    "\n",
    "(cyc_base + cyc_fit).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrf = df.copy()\n",
    "\n",
    "dfrf[\"minute\"] = pd.to_datetime(df[\"collision_time\"], format = \"%H:%M:%S\").dt.minute\n",
    "dfrf[\"day\"] = pd.to_datetime(df[\"collision_time\"], format = \"%H:%M:%S\").dt.day_of_year\n",
    "\n",
    "\n",
    "drop_feats = [\"collision_severity\", \"killed_victims\", \"injured_victims\", \"severe_injury_count\",\n",
    "              \"other_visible_injury_count\", \"complaint_of_pain_injury_count\", \"pedestrian_killed_count\", \"pedestrian_injured_count\",\n",
    "              \"bicyclist_killed_count\", \"bicyclist_injured_count\", \"motorcyclist_killed_count\", \"motorcyclist_injured_count\",\n",
    "              \"case_id\", \"process_date\", \"hour\", \"collision_date\", \"process_date\", \"collision_time\",\n",
    "              \"city_division_lapd\", \"caltrans_county\", \"caltrans_district\", \"state_route\", \"postmile\"]\n",
    "\n",
    "dfnan = pd.DataFrame()\n",
    "dfnan[\"predictor\"] = (dfrf.isna().sum() / dfrf.isna().count()).sort_values().index\n",
    "dfnan[\"p_nan\"] = (dfrf.isna().sum() / dfrf.isna().count()).sort_values().values\n",
    "\n",
    "drop_nans = dfnan.query(\"p_nan > 0.8\")[\"predictor\"] # drop features that are more than 80 % nan\n",
    "\n",
    "X = dfrf.drop(drop_feats, axis = 1).drop(drop_nans, axis = 1).convert_dtypes()\n",
    "\n",
    "numcols = []\n",
    "for column in X:\n",
    "    if X[column].dtype != \"string[python]\":\n",
    "        numcols.append(column)\n",
    "badnumcols = [column for column in numcols if column not in [\"distance\", \"party_count\", \"latitude\", \"longitude\", \"year\", \"minute\", \"day\"]] # only keep these ones as numeric\n",
    "X[badnumcols] = X[badnumcols].astype(\"string[python]\")\n",
    "\n",
    "badcats = [column for column in X if X[column].nunique() > 100 and X[column].dtype == \"string[python]\"]\n",
    "X = X.drop(badcats, axis = 1) # drop categorical features with more than 100 unique groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfnan.sort_values(\"p_nan\")).mark_bar().encode(\n",
    "    x = alt.X(\"predictor\", sort = \"y\", title = \"Feature\").axis(labelAngle = 50, labelFontSize = 12),\n",
    "    y = alt.Y(\"p_nan\", title = \"Percent missing rows\")\n",
    ").properties(width = 1000, height = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding number of unique groups for categorical features\n",
    "\n",
    "strcolumns = []\n",
    "for column in X:\n",
    "    if X[column].dtype == \"string[python]\":\n",
    "        strcolumns.append(column)\n",
    "\n",
    "columns, uniques = [], []\n",
    "\n",
    "for column in strcolumns:\n",
    "    columns.append(column)\n",
    "    uniques.append(len(X[column].value_counts()))\n",
    "                   \n",
    "opdf = pd.DataFrame({\"column\": columns, \"unique\": uniques})\n",
    "\n",
    "badcats = opdf.query(\"unique > 100\")[\"column\"].values\n",
    "uns = opdf.sort_values(\"unique\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(uns).mark_bar().encode(\n",
    "    x = alt.X(\"column\", sort = \"y\"),\n",
    "    y = alt.Y(\"unique\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh = pd.get_dummies(X)\n",
    "y = dfrf[\"injured_victims\"].fillna(0)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(Xoh, y, random_state = 13)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff = rf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df.columns.values.reshape(15, 5))\n",
    "\n",
    "varlist = list(X.columns) + [\" \", \" \"]\n",
    "pd.DataFrame(np.reshape(varlist, (9, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred = rff.predict(X_te)\n",
    "\n",
    "print(\"RMSE: %.3f\" % (np.sqrt(mean_squared_error(y_te, rfpred))))\n",
    "print(\"Proportion correct: %.3f \"% ((y_te == rfpred.astype(int)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cf = confusion_matrix(y_te, rfpred.astype(int))\n",
    "\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cf)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "cmp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"feature\": rff.feature_names_in_, \"importance\": rff.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh2 = pd.get_dummies(X.drop(\"party_count\", axis = 1))\n",
    "y2 = dfrf[\"injured_victims\"].fillna(0) / dfrf[\"party_count\"].fillna(1) # repeating this time using the injuries per party involved\n",
    "\n",
    "X2_tr, X2_te, y2_tr, y2_te = train_test_split(Xoh2, y2, random_state = 13)\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff2 = rf2.fit(X2_tr, y2_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred2 = rff2.predict(X2_te)\n",
    "\n",
    "print(\"RMSE: %.3f\" % (np.sqrt(mean_squared_error(y2_te, rfpred2))))\n",
    "print(\"Proportion correct: %.3f \"% ((y2_te == rfpred2.astype(int)).mean()))\n",
    "\n",
    "pd.DataFrame({\"feature\": rff2.feature_names_in_, \"importance\": rff2.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh3 = pd.get_dummies(X)\n",
    "y3 = dfrf[\"collision_severity\"] # repeating this time using categorical label\n",
    "\n",
    "X3_tr, X3_te, y3_tr, y3_te = train_test_split(Xoh3, y3, random_state = 13)\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff3 = rf3.fit(X3_tr, y3_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred3 = rff3.predict(X3_te)\n",
    "\n",
    "print(\"Proportion correct: %.3f \"% ((y3_te == rfpred3).mean()))\n",
    "\n",
    "cf3 = confusion_matrix(y3_te, rfpred3)\n",
    "\n",
    "cmp3 = ConfusionMatrixDisplay(confusion_matrix=cf3, display_labels=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmp3.plot(ax=ax)\n",
    "\n",
    "pd.DataFrame({\"feature\": rff3.feature_names_in_, \"importance\": rff3.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: fatal, 1: other injury, 2: pain, 3: property damage only, 4: severe injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y3_te.value_counts())\n",
    "\n",
    "for row in cf3:\n",
    "    print(row.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanidf = dfc[[\"hour\", \"injured_victims\"]].groupby(\"hour\").mean().reset_index()\n",
    "sumidf = dfc[[\"hour\", \"injured_victims\"]].groupby(\"hour\").sum().reset_index()\n",
    "\n",
    "imean = alt.Chart(meanidf).mark_bar(width = 30, color = \"darkred\").encode(\n",
    "    x = alt.X(\"hour:O\"),\n",
    "    y = alt.Y(\"injured_victims\", title = \"mean injured victims per collision\").stack(None)\n",
    ").properties(width = 800, height = 140)\n",
    "\n",
    "isum = alt.Chart(sumidf).mark_bar(width = 30, color = \"darkred\").encode(\n",
    "    x = alt.X(\"hour:O\"),\n",
    "    y = alt.Y(\"injured_victims\", title = \"total injured victims per hour\").stack(None)\n",
    ").properties(width = 800, height = 140)\n",
    "\n",
    "(imean & isum).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhr = dfc[[\"injured_victims\", \"hit_and_run\"]]\n",
    "\n",
    "alt.Chart(dfhr).mark_line().encode(\n",
    "    x = alt.X(\"injured_victims\", title = \"Number of injured victims\"),\n",
    "    y = alt.Y(\"count()\").stack(None).scale(type = \"log\"),\n",
    "    color = \"hit_and_run\"\n",
    ").properties(width = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhr\n",
    "\n",
    "dfhr.query(\"hit_and_run == 'not hit and run'\").groupby(\"injured_victims\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdis = dfc[[\"injured_victims\", \"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfdis).mark_circle().encode(\n",
    "    x = alt.X(\"distance\"),\n",
    "    y = alt.Y(\"injured_victims\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
