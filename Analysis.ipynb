{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import altair as alt\n",
    "import scipy.interpolate as interpolate\n",
    "from scipy.stats import skewnorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seamu\\AppData\\Local\\Temp\\ipykernel_22800\\3209997596.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"hour\"] = pd.to_datetime(df[\"collision_time\"]).dt.hour\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(\"switrs.sqlite\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM collisions WHERE county_location = 'los angeles'\n",
    "    \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, con, parse_dates = [\"collision_date\"])\n",
    "df[\"year\"] = df[\"collision_date\"].dt.year\n",
    "df[\"hour\"] = pd.to_datetime(df[\"collision_time\"]).dt.hour\n",
    "df = df.query(\"year < 2021\") # remove incomplete 2021 data\n",
    "df[\"alcohol_involved\"] = df[\"alcohol_involved\"].fillna(0) # convert NaN to 0 in alcohol use column\n",
    "\n",
    "dfc = df[[\"case_id\", \"county_location\", \"alcohol_involved\", \"collision_severity\", \"injured_victims\", \"collision_date\", \"year\", \"collision_time\", \"hour\", \"party_count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of the proportion of crashes involving alcohol by time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will attempt to use multiple models to fit this distribution. We will use polynomial splines and B-splines but it appears a skewed-normal may be a possible fit as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions of the number of injuries per collision, alcohol vs. no alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These appear to follow exponential or Weibull distributions. We will determine which is the best fit and then compare to see if alcohol has an effect on the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeline for number of collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on up to 2019, predict 2020, compare to actual. This will be done using a time series model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeline for number of collisions (alcohol vs no alcohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained on up to 2019, predicting 2020, but separating by alcohol vs. no alcohol and comparing to actuals. This will also be completed using a time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection using LASSO on fitted GLM against several labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection using Random Forest feature importance against several labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrf = df.copy()\n",
    "\n",
    "dfrf[\"minute\"] = pd.to_datetime(df[\"collision_time\"], format = \"%H:%M:%S\").dt.minute\n",
    "dfrf[\"day\"] = pd.to_datetime(df[\"collision_time\"], format = \"%H:%M:%S\").dt.day_of_year\n",
    "\n",
    "\n",
    "drop_feats = [\"collision_severity\", \"killed_victims\", \"injured_victims\", \"severe_injury_count\",\n",
    "              \"other_visible_injury_count\", \"complaint_of_pain_injury_count\", \"pedestrian_killed_count\", \"pedestrian_injured_count\",\n",
    "              \"bicyclist_killed_count\", \"bicyclist_injured_count\", \"motorcyclist_killed_count\", \"motorcyclist_injured_count\",\n",
    "              \"case_id\", \"process_date\", \"hour\", \"collision_date\", \"process_date\", \"collision_time\",\n",
    "              \"city_division_lapd\", \"caltrans_county\", \"caltrans_district\", \"state_route\", \"postmile\"]\n",
    "\n",
    "dfnan = pd.DataFrame()\n",
    "dfnan[\"predictor\"] = (dfrf.isna().sum() / dfrf.isna().count()).sort_values().index\n",
    "dfnan[\"p_nan\"] = (dfrf.isna().sum() / dfrf.isna().count()).sort_values().values\n",
    "\n",
    "drop_nans = dfnan.query(\"p_nan > 0.8\")[\"predictor\"] # drop features that are more than 80 % nan\n",
    "\n",
    "X = dfrf.drop(drop_feats, axis = 1).drop(drop_nans, axis = 1).convert_dtypes()\n",
    "\n",
    "numcols = []\n",
    "for column in X:\n",
    "    if X[column].dtype != \"string[python]\":\n",
    "        numcols.append(column)\n",
    "badnumcols = [column for column in numcols if column not in [\"distance\", \"party_count\", \"latitude\", \"longitude\", \"year\", \"minute\", \"day\"]] # only keep these ones as numeric\n",
    "X[badnumcols] = X[badnumcols].astype(\"string[python]\")\n",
    "\n",
    "badcats = [column for column in X if X[column].nunique() > 100 and X[column].dtype == \"string[python]\"]\n",
    "X = X.drop(badcats, axis = 1) # drop categorical features with more than 100 unique groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding number of unique groups for categorical features\n",
    "\n",
    "strcolumns = []\n",
    "for column in X:\n",
    "    if X[column].dtype == \"string[python]\":\n",
    "        strcolumns.append(column)\n",
    "\n",
    "columns, uniques = [], []\n",
    "\n",
    "for column in strcolumns:\n",
    "    columns.append(column)\n",
    "    uniques.append(len(X[column].value_counts()))\n",
    "                   \n",
    "opdf = pd.DataFrame({\"column\": columns, \"unique\": uniques})\n",
    "\n",
    "badcats = opdf.query(\"unique > 100\")[\"column\"].values\n",
    "uns = opdf.sort_values(\"unique\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh = pd.get_dummies(X)\n",
    "y = dfrf[\"injured_victims\"].fillna(0)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(Xoh, y, random_state = 13)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff = rf.fit(X_tr, y_tr)\n",
    "\n",
    "rfpred = rff.predict(X_te)\n",
    "\n",
    "print(\"RMSE: %.3f\" % (np.sqrt(mean_squared_error(y_te, rfpred))))\n",
    "print(\"Proportion correct: %.3f \"% ((y_te == rfpred.astype(int)).mean()))\n",
    "\n",
    "pd.DataFrame({\"feature\": rff.feature_names_in_, \"importance\": rff.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh2 = pd.get_dummies(X.drop(\"party_count\", axis = 1))\n",
    "y2 = dfrf[\"injured_victims\"].fillna(0) / dfrf[\"party_count\"].fillna(1) # repeating this time using the injuries per party involved\n",
    "\n",
    "X2_tr, X2_te, y2_tr, y2_te = train_test_split(Xoh2, y2, random_state = 13)\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff2 = rf2.fit(X2_tr, y2_tr)\n",
    "\n",
    "rfpred2 = rff2.predict(X2_te)\n",
    "\n",
    "print(\"RMSE: %.3f\" % (np.sqrt(mean_squared_error(y2_te, rfpred2))))\n",
    "print(\"Proportion correct: %.3f \"% ((y2_te == rfpred2.astype(int)).mean()))\n",
    "\n",
    "pd.DataFrame({\"feature\": rff2.feature_names_in_, \"importance\": rff2.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh3 = pd.get_dummies(X)\n",
    "y3 = dfrf[\"collision_severity\"] # repeating this time using categorical label\n",
    "\n",
    "X3_tr, X3_te, y3_tr, y3_te = train_test_split(Xoh3, y3, random_state = 13)\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators = 10, random_state = 13)\n",
    "\n",
    "rff3 = rf3.fit(X3_tr, y3_tr)\n",
    "\n",
    "rfpred3 = rff3.predict(X3_te)\n",
    "\n",
    "print(\"Proportion correct: %.3f \"% ((y3_te == rfpred3).mean()))\n",
    "\n",
    "cf3 = confusion_matrix(y3_te, rfpred3)\n",
    "\n",
    "cmp3 = ConfusionMatrixDisplay(confusion_matrix=cf3, display_labels=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmp3.plot(ax=ax)\n",
    "\n",
    "pd.DataFrame({\"feature\": rff3.feature_names_in_, \"importance\": rff3.feature_importances_}).sort_values(\"importance\", ascending = False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
